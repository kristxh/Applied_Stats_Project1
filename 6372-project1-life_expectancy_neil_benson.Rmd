---
title: "6372 Project 1 - Life Expectancy"
author: "By Kristi Herman, Bo Yun, Eric Romero, Neil Benson"
date: "09/20/2020"
output:
  html_document:
    df_print: paged
---
  
# Introduction
Introduction paragraphs here


## Importing the necessary libraries
```{r,warning=FALSE,message=FALSE}

library(ggplot2)
library(ggthemes)
library(gridExtra)
library(tidyverse)
library(plyr)
library(dplyr) 
library(naniar) #keep
library(zoo)


# create not in operator
`%notin%` <- Negate(`%in%`)

```
## Introduction
What factors impact life expectancy?  Can life expectancy be predicted?  The World Health Organization (WHO) maintains a database with life expectancy information for all countries by year along with other variables that could contribute to life expectancy.  The data falls into four main areas:  health, economic, social, and immunization.  This project makes use of the WHO data to better understand life expectancy and how to predict it.  In this paper, three different models will be explored:
1)      A regression model to identify key relationships between life expectancy and factors related to health, economic, social, and immunization.
2)      A parametric regression model to predict life expectancy.
3)      A non-parametric regression model to predict life expectancy.


## Data Description
The Life Expectancy dataset used in this analysis was collected from the WHO and made available at Kaggle:  https://www.kaggle.com/kumarajarshi/life-expectancy-who.  It includes data from 193 countries for the years 2000 â€“ 2015.  The 2938 rows contained in the dataset include average life expectancy per country for each year.  In addition to the average life expectancy, there are 21 columns of data related to health, economic, social, and immunization.   


## Exploratory Data Analysis
  
## Importing and Cleaning the Data
```{r, warning=FALSE, message=FALSE}
########### Loading the data
life_ex_DF <- read.csv("https://raw.githubusercontent.com/kristxh/Applied_Stats_Project1/master/datasets_12603_17232_Life_Expectancy_Data.csv")

# cleaning up column names
colnames(life_ex_DF) <- tolower(colnames(life_ex_DF))
colnames(life_ex_DF) <- gsub("\\.\\.",".",colnames(life_ex_DF))
colnames(life_ex_DF) <- gsub("\\.","_",colnames(life_ex_DF))
names(life_ex_DF)[19] <- "thinness_10_19_years"

# converting status and year to factor columns
life_ex_DF$status <- as.factor(life_ex_DF$status)
```


## checking for missing data
```{r}
# checking for missing values in the data
vis_miss(life_ex_DF) + xlab("Data Columns")
```
  
  
## fix missing data
```{r, fig.height=9, fig.width=9}
# sorting the columns so that life_expectancy column is first
life_ex_DF <- life_ex_DF %>% select("life_expectancy", everything())

factorcols <- c("status","country","year")
allcols <- colnames(life_ex_DF)

# selecting only numerical columns for correlation
corvars <- allcols[allcols %notin% factorcols]


# impute with median missing values per country
life_ex_median_DF <- as.data.frame(life_ex_DF %>%
  group_by(country) %>%
  mutate_at(corvars, na.aggregate, FUN=median))


# dropping rows where the country has a single entry/record in the dataset and their records are mostly incomplete
life_ex_median_DF <- life_ex_median_DF[!is.na(life_ex_median_DF$life_expectancy), ]


# imputing the median by country still left a few nulls throughout. We will then impute the rest of the missing values as the mean of stats (developpoing, developed, by year)
life_ex_cleaned_DF <- as.data.frame(life_ex_median_DF %>%
  group_by(status,year) %>%
  mutate_at(corvars, na.aggregate, FUN=median))

# checking for missing values in the data
vis_miss(life_ex_cleaned_DF) + xlab("Data Columns")
```


# summary of cleaned up data
```{r}
summary(life_ex_cleaned_DF)
str(life_ex_cleaned_DF)

t(aggregate(life_expectancy~status,data=life_ex_cleaned_DF,summary))
t(aggregate(life_expectancy~status,data=life_ex_cleaned_DF,sd))
```


# histogram of life_expectancy
```{r}
theme_set(theme_igray())

le_hist <- geom_histogram(
  mapping = aes(life_expectancy),
  data = life_ex_cleaned_DF,
  bins = 20,
  colour = "gray",
  fill = "#0072B2"
)

ggplot()+ le_hist + xlab("Years") + ggtitle("Life Expectancy")

```


# Overall Life Expectancy
```{r}

le_by_yr <- ddply(life_ex_cleaned_DF, .(year), summarize,  avg_le=mean(life_expectancy))

le_line <- geom_line(
  mapping = aes(x = year, y = avg_le),
  data = le_by_yr,
  size = 1,
  colour = "dodgerblue4"
)

ggplot() + le_line + xlab("Year") + ylab("Life Expectancy") + ggtitle("Average Life Expectancy: 2000 - 2015") 

```


# Developed/Developing Life Expectancy
```{r visual1, fig.width=20, fig.height=10}
le_by_status <- ddply(life_ex_cleaned_DF, .(year,status), summarize,  avg_le=mean(life_expectancy))
line_colors <- c("dodgerblue4", "#D55E00")

le_line2 <- geom_line(
  mapping = aes(x = year, y = avg_le, group=status, color=status),
  data = le_by_status,
  size = 1
)

ggplot() + le_line2 +  xlab("Year") + ylab("Life Expectancy") + ggtitle("Average Life Expectancy: Developed and Developing Countries") + scale_colour_manual(values=line_colors)

```


# boxplot by status (developing, developed)
```{r visual2, fig.width=6, fig.height=6}
# Plot boxplot

dev_box <- geom_boxplot(
  mapping = aes(x=status, y=life_expectancy),
  data = life_ex_cleaned_DF,
  colour = "black",
  fill = "#56B4E9",
  groupColors=c('#999999','#E69F00')
)

ggplot()+ dev_box + xlab("Status of Country") + ylab("Life Expectancy") + ggtitle("Life Expectancy: Developed and Developing Countries ")

```


# boxplots by status by year
```{r visual3, fig.width=10, fig.height=6}
# Plot boxplot

yr_box <- stat_boxplot(
  mapping = aes(x=year, y=life_expectancy, group=year),
  data = life_ex_cleaned_DF,
  colour = "black",
  fill = "#56B4E9"
  ) 
  

ggplot()+ yr_box + xlab("Year") + ylab("Life Expectancy") + scale_x_continuous(breaks=c(2000:2015)) + ggtitle("Life Expectancy by Year")  
```
```{r fig.width=10, fig.height=6}
# Scatterplot boxplot

le_scatter <- geom_point(
  mapping = aes(x=year, y=life_expectancy, color=status),
  data = life_ex_cleaned_DF
  ) 
  

ggplot()+ le_scatter + xlab("Year") + ylab("Life Expectancy") + scale_x_continuous(breaks=c(2000:2015)) + ggtitle("Life Expectancy: Developed and Developing Countries")  + scale_colour_manual(values=line_colors)
```


# correlation matrix with pearson correlation coefficients
```{r, fig.height=9, fig.width=9}
library(reshape2)

corr <- round(cor(life_ex_cleaned_DF[,corvars]),1)
melted_cormat <- melt(corr)


# Get lower triangle of the correlation matrix
  get_lower_tri<-function(cormat){
    cormat[lower.tri(cormat)] <- NA
    return(cormat)
  }
  

# reorder the correlation matrix
reorder_cormat <- function(cormat){
# Use correlation between variables as distance
dd <- as.dist((1-cormat)/2)
hc <- hclust(dd)
cormat <-cormat[hc$order, hc$order]
}


# reorder the correlation matrix
corr <- reorder_cormat(corr)

# get lower half
lower_half <- get_lower_tri(corr)

# reshape the correlation matrix
melted_cormat <- melt(lower_half, na.rm = TRUE)

# plot it
ggcorrmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
 geom_tile(color = "white")+
 scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
  midpoint = 0, limit = c(-1,1), space = "Lab", 
    name="Pearson\nCorrelation") +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 8, hjust = 1), axis.title.x = element_blank(), axis.title.y = element_blank())+
 coord_fixed()


ggcorrmap + geom_text(aes(Var2, Var1, label = value), color = "black", size = 2.5)
```
It appears there is a high degree of correlation between the following:  
- thinnes_5_9_years and thinnes_5_9_years
- percentage_expenditure and gdp
- under_5_deaths and infant_deaths
- schooling and income_composition_of_resources
- population has 0 correlation with the response variable and will be removed as a predictor and is incomplete throughout the data set


# further examining the issue of multicolinearity
```{r, fig.height=9, fig.width=9}
pairs(life_ex_cleaned_DF[,corvars], pch = 19,  cex = 0.5,
      col = line_colors[life_ex_cleaned_DF$status],
      upper.panel=NULL)

```


# checking colinearity with VIF and removing redundant columns
```{r}
library(car)

full.model <- lm(life_expectancy~. ,data=life_ex_cleaned_DF[,corvars])

vif(full.model, data = life_ex_cleaned_DF)

# removing columns and re-evaluating
colstodelete <- c("under_five_deaths", "thinness_5_9_years", "gdp", "population")

full.model1 <- lm(life_expectancy~. ,data=life_ex_cleaned_DF[,corvars] %>% select(-colstodelete))

vif(full.model1, data = life_ex_cleaned_DF[,corvars] %>% select(-all_of(colstodelete)))

```
infant_deaths and under_five_deaths have a VIF of 177.36 and 176.35 respectively, indicating a very high degree of 
multicolinearity between the two. We will remove under_five_deaths and re-evaluate.

thinness_5_9_years and thinness_10_19_years have a VIF of 8.82 and 8.74 respectively, indicating a very high degree of 
multicolinearity between the two. We will remove thinness_5_9_years and re-evaluate.

percentage_expenditure and gdp have a VIF of 4.92 and 5.32 respectively, indicating a very high degree of 
multicolinearity between the two. We will remove gdp and re-evaluate.

schooling and income_composition_of_resources have are correlated to each with Pearson Correlation Coefficient of .8, but have VIFs
of 3.62 and 3.05. While these are highly correlated, their VIFs are relatively low. We will leave them in them in for variable selection.


# checking the significance of the factorial variables using ANOVA
```{r}
# convert categorical variables to factors
names <- c("country", "year", "status")

life_ex_cleaned_factor_DF <- life_ex_cleaned_DF

# set the categorical columns to factor
for (name in names)
{
  life_ex_cleaned_factor_DF[,name]<-factor(life_ex_cleaned_DF[,name])
}

# convert factors to numeric for factor analysis
life_ex_cleaned_asnum_DF <- life_ex_cleaned_factor_DF[,names] %>% mutate_all(as.numeric)

# adding suffix ASNUM to numerical representation of factors columns
colnames(life_ex_cleaned_asnum_DF) <- paste(colnames(life_ex_cleaned_asnum_DF), "ASNUM", sep = "_")

# adding numerical factor columns to base Df in order to perform stepwise for variable selection
life_ex_cleaned_withnum_DF <- cbind(life_ex_cleaned_factor_DF, life_ex_cleaned_asnum_DF)

# dropping factor columns
life_ex_cleaned_withnum_DF <- life_ex_cleaned_withnum_DF[, sapply(life_ex_cleaned_withnum_DF, class) != "factor"]

#  columns for anova factor analysis
anovacols <- c(colnames(life_ex_cleaned_asnum_DF))

#  creating the formula to pass into aov function
anovafmla <- as.formula(paste("life_expectancy ~ ", paste(anovacols, collapse= "+")))

# passing my auto generated formula to analyze
anova_fit <- aov(anovafmla, data=life_ex_cleaned_withnum_DF)
summary(anova_fit)
```
Both year and status are statistically significant as categorical predictors. 
We will remove country from the data set for variable selection.


# removing columns with high colinearity or low significance
```{r}
# adding "country" to the list of columns to delete after its poor performance in ANOVA analysis
colstodelete <- append(colstodelete, "country")  

Life <- life_ex_cleaned_factor_DF %>% select(-colstodelete) 

# Checking residuals and q-q plot
par(mfrow=c(2,2))
plot(full.model)
```


# splitting the data into test and training sets for cross validation
```{r}
# Cross Validation on Train vs Test 
# Splitting 2939 observations of the data into Training and Test set in the ratio of 70:30
set.seed(1234)
trainIndices = sample(seq(1:dim(Life)[1]),round(.7*dim(Life)[1]))
train = Life[trainIndices,]
test = Life[-trainIndices,]
dim(train)
dim(test)
```


# creating a prediction function
```{r}
predict.regsubsets = function (object , newdata ,id ,...){
  form=as.formula (object$call [[2]])
  mat=model.matrix(form ,newdata )
  coefi=coef(object ,id=id)
  xvars=names(coefi)
  mat[,xvars]%*%coefi
}
```


# Variable selection - Forward 
```{r}
# Just the training set
library(leaps)

reg.fwd=regsubsets(life_expectancy~.,data=train,method="forward",nvmax=14)

par(mfrow=c(1,3))

bics<-summary(reg.fwd)$bic

plot(1:14,bics,type="l",ylab="BIC",xlab="# of predictors")

index<-which(bics==min(bics))

points(index,bics[index],col="red",pch=10)

adjr2<-summary(reg.fwd)$adjr2

plot(1:14,adjr2,type="l",ylab="Adjusted R-squared",xlab="# of predictors")

index<-which(adjr2==max(adjr2))

points(index,adjr2[index],col="red",pch=10)

rss<-summary(reg.fwd)$rss

plot(1:14,rss,type="l",ylab="train RSS",xlab="# of predictors")

index<-which(rss==min(rss))

points(index,rss[index],col="red",pch=10)

mtext("Variable selection - Forward", side = 3, line = -2, outer = TRUE)

# -> 11 predictors
```


# Variable selection - Backward
```{r}
# Just the training set
reg.bwd=regsubsets(life_expectancy~.,data=train,method="backward",nvmax=14)

par(mfrow=c(1,3))

bics2<-summary(reg.bwd)$bic

plot(1:14,bics2,type="l",ylab="BIC",xlab="# of predictors")

index2<-which(bics2==min(bics2))

points(index2,bics2[index2],col="red",pch=10)

adjr2<-summary(reg.bwd)$adjr2

plot(1:14,adjr2,type="l",ylab="Adjusted R-squared",xlab="# of predictors")

index.r2<-which(adjr2==max(adjr2))

points(index.r2,adjr2[index.r2],col="red",pch=10)

rss2<-summary(reg.bwd)$rss

plot(1:14,rss2,type="l",ylab="train RSS",xlab="# of predictors")

index.rss2<-which(rss2==min(rss2))

points(index.rss2,rss[index.rss2],col="red",pch=10)

mtext("Variable selection - Backward", side = 3, line = -2, outer = TRUE)

# -> 11 predictors
```


# Variable selection - Stepwise
```{r}
# Just the training set
reg.stp=regsubsets(life_expectancy~.,data=train,method="seqrep",nvmax=14)

par(mfrow=c(1,3))

bics3<-summary(reg.stp)$bic

plot(1:14,bics,type="l",ylab="BIC",xlab="# of predictors")

index3<-which(bics3==min(bics3))

points(index3,bics[index3],col="red",pch=10)

adjr3<-summary(reg.stp)$adjr

plot(1:14,adjr3,type="l",ylab="Adjusted R-squared",xlab="# of predictors")

index3<-which(adjr3==max(adjr3))

points(index3,adjr3[index3],col="red",pch=10)

rss3<-summary(reg.stp)$rss

plot(1:14,rss3,type="l",ylab="train RSS",xlab="# of predictors")

index3<-which(rss3==min(rss3))

points(index3,rss[index3],col="red",pch=10)

mtext("Variable selection - Stepwise", side = 3, line = -2, outer = TRUE)

# -> 11 predictors
```


# Variable selection - LASSO
```{r}
library(glmnet)

x=model.matrix(life_expectancy~.,train)[,-1]
y=train$life_expectancy

xtest<-model.matrix(life_expectancy~.,test)[,-1]
ytest<-test$life_expectancy

grid=10^seq(10,-2, length =100)
lasso.mod=glmnet(x,y,alpha=1, lambda =grid)


# LASSO regularization and rsquare plot
plot(lasso.mod,xvar="lambda",label=TRUE)  # shows shrinkage and variable selection
plot(lasso.mod,xvar="dev",label=TRUE)  # shows rsquare change as the number of variable changes

# CV plot for LASSO
cv.out=cv.glmnet(x,y,alpha=1) #alpha=1 performs LASSO
plot(cv.out) #The output has 11 non-zero coefficients which shows that the function has chosen the second vertical second line on the cross-validation plot (within one standard error of the minimum) because cross validation error is measured with some variance.

# Two vertical lines.
# 1. The one is at the minimum(the one at 18)
# 2. The other vertical line is within one standard error of the minimum(the one at 11). We have this line because cross validation error is measured with some variance. 

# => The result chose the second line of 11 variables as seen in the plot(cv.out)

bestlambda<-cv.out$lambda.min  #Optimal penalty parameter.  You can make this call visually.
lasso.pred=predict (lasso.mod ,s=bestlambda ,newx=xtest)

testMSE_LASSO<-mean((ytest-lasso.pred)^2)
testMSE_LASSO


#Coefficients of the lasso model - Shows 11 variables (10 explanatory variables + 1 intercept), here's a coefficient function extractor that works on a cross validation object and pick the coefficient vector corresponding to the best model
coef(lasso.mod,s=bestlambda)   

# Recreating the final LASSO model based on variable selection
reg.lso <- lm(life_expectancy~. -year -hepatitis_b, data=Life)
```


# cross validating the models 
```{r}
testASEfwd<-c()
testASEbwd<-c()
testASEstp<-c()

for (i in 1:14){
  # predicting the forward model on test set
  predictionsfwd<-predict.regsubsets(object=reg.fwd,newdata=test,id=i)
  testASEfwd[i]<-mean((test$life_expectancy-predictionsfwd)^2)
  
  # predicting the backward model on test set
  predictionsbwd<-predict.regsubsets(object=reg.bwd,newdata=test,id=i)
  testASEbwd[i]<-mean((test$life_expectancy-predictionsbwd)^2)
  
  # predicting stepwise model on test set
  predictionsstp<-predict.regsubsets(object=reg.stp,newdata=test,id=i)
  testASEstp[i]<-mean((test$life_expectancy-predictionsstp)^2)
  
}

```


# plots for something - ASE
```{r}
par(mfrow=c(1,1))
plot(1:14,testASEfwd,type="l",xlab="# of predictors",ylab="test vs train ASE",ylim=c(10,50))
index<-which(testASEfwd==min(testASEfwd))
points(index,testASEfwd[index],col="red",pch=10)
rss<-summary(reg.fwd)$rss
lines(1:14,rss/2928,lty=3,col="blue")  #Dividing by 2928 since ASE=RSS/sample size
mtext("ASE - Forward", side = 3, line = -2, outer = TRUE)


par(mfrow=c(1,1))
plot(1:14,testASEbwd,type="l",xlab="# of predictors",ylab="test vs train ASE",ylim=c(10,50))
index<-which(testASEbwd==min(testASEbwd))
points(index,testASEbwd[index],col="red",pch=10)
rss<-summary(reg.bwd)$rss
lines(1:14,rss/2928,lty=3,col="blue")  #Dividing by 2928 since ASE=RSS/sample size
mtext("ASE - Backward", side = 3, line = -2, outer = TRUE)


par(mfrow=c(1,1))
plot(1:14,testASEstp,type="l",xlab="# of predictors",ylab="test vs train ASE",ylim=c(10,50))
index<-which(testASEstp==min(testASEstp))
points(index,testASEstp[index],col="red",pch=10)
rss3<-summary(reg.stp)$rss3
lines(1:14,rss/2928,lty=3,col="blue")  #Dividing by 2928 since ASE=RSS/sample size
mtext("ASE - Stepwise", side = 3, line = -2, outer = TRUE)
```


# Using forward backward, and stepwise to select max number of variables:11
```{r}
# final variable selection for forward variable selection
reg.finalfwd=regsubsets(life_expectancy~.,data=Life,method="forward",nvmax=11)
coef(reg.finalfwd,10)

final.modelfwd<-lm(life_expectancy~ status + year + adult_mortality + percentage_expenditure + measles + bmi + polio + diphtheria + hiv_aids + income_composition_of_resources + schooling, data=Life)

summary(final.modelfwd)

plot(final.modelfwd$fitted.values,Life$life_expectancy,xlab="Predicted",ylab="Life Expectancy",xlim=c(20,110),ylim=c(20,110) )
lines(c(20,110),c(20,110),col="red")
mtext("Forward", side = 3, line = -2, outer = TRUE)




# final variable selection for backward variable selection - the forward and backwards method selected the same model in this case
reg.finalbwd=regsubsets(life_expectancy~. ,data=Life,method="backward",nvmax=11)
coef(reg.finalbwd,10)

final.modelbwd<-lm(life_expectancy~ status + year + adult_mortality + percentage_expenditure + measles + bmi + polio + diphtheria + hiv_aids + income_composition_of_resources + schooling,data=Life)

summary(final.modelbwd)


plot(final.modelbwd$fitted.values,Life$life_expectancy,xlab="Predicted",ylab="Life Expectancy",xlim=c(20,110),ylim=c(20,110))
lines(c(20,110),c(20,110),col="red")
mtext("Backward", side = 3, line = -2, outer = TRUE)




# final variable selection for stepwise variable selection
reg.finalstp=regsubsets(life_expectancy~.,data=Life,method="seqrep",nvmax=11)
coef(reg.finalstp,10)

final.modelstp <- lm(life_expectancy~.-total_expenditure -hepatitis_b -alcohol -infant_deaths, data=Life)

summary(final.modelstp)

plot(final.modelstp$fitted.values,Life$life_expectancy,xlab="Predicted",ylab="Life Expectancy",xlim=c(20,110),ylim=c(20,110) )
lines(c(20,110),c(20,110),col="red")
mtext("Stepwise", side = 3, line = -2, outer = TRUE)


# final variable selection for lasso variable selection
final.modellso <- reg.lso

summary(final.modellso)

plot(final.modellso$fitted.values,Life$life_expectancy,xlab="Predicted",ylab="Life Expectancy",xlim=c(20,110),ylim=c(20,110), na.rm = TRUE )
lines(c(20,110),c(20,110),col="red")
mtext("Lasso", side = 3, line = -2, outer = TRUE)
```


# comparing the models
```{r}

# Function for Root Mean Squared Error
RMSE <- function(error) { sqrt(mean(error^2)) }

RMSE(final.modelfwd$residuals)
RMSE(final.modelbwd$residuals)
RMSE(final.modelstp$residuals)
RMSE(final.modellso$residuals)


summary(final.modelfwd)$adj.r.squared
summary(final.modelbwd)$adj.r.squared
summary(final.modelstp)$adj.r.squared
summary(final.modellso)$adj.r.squared

AIC(final.modelfwd,final.modelbwd, final.modelstp, final.modellso)
BIC(final.modelfwd,final.modelbwd, final.modelstp, final.modellso)
```
## Option 1 for interpretable model
Quesiton of Interest:  Is there a relationship between schooling and life expectancy?  If so, is there an interaction with status?

## Model Selection
Question of Interest

```{r}
# Cross Validation on Train vs Test 
# Splitting 2939 observations of the data into Training and Test set in the ratio of 70:30
set.seed(1234)
trainIndices = sample(seq(1:dim(Life)[1]),round(.7*dim(Life)[1]))
train = Life[trainIndices,]
test = Life[-trainIndices,]

```

```{r}
model_fit <- lm(life_expectancy ~ schooling + status + status*schooling, data=train)
summary(model_fit)

model_pre <- predict(model_fit, interval = "predict", newdata=test)
model_pre

```


## Checking Assumptions

There is a strong linear relationship between schooling and life_expectancy
```{r fig.width=10,fig.height=10}
ggplot(life_exp_wo_0, aes(x=schooling, y = life_expectancy)) + geom_point() + geom_smooth(method= "lm");

```

There is visual evidence of an interaction between status and schooling
```{r fig.width=10,fig.height=10}
ggplot(life_exp_wo_0, aes(x=schooling, y = life_expectancy, colour = status)) + geom_point() + geom_smooth(method= "lm") + scale_color_manual(values = c("dodgerblue4", "#D55E00"));
```

```{r}
MSPE <- mean((model_pre[,1] - test$life_expectancy)^2)
MSPE
            
```
## Checking Residuals and Normality
There are 22 outliers with "O" schooling.  Based on other data for the countries that are missing data, it seems that data may not have been gathered for the years with a 0 value for schooling.  The outliers were left in because they do not have high influence.
```{r}
par(mfrow=c(2,2))
plot(model_fit)
summary(Life$schooling)

res <- resid(model_fit)
plot(Life$life_expectancy, res, xlab = "X",ylab = "Residual", main = "Residuals")
```
```{r}
mysummary<-function(x){
  result<-c(length(x),mean(x),sd(x),sd(x)/length(x), min(x), max(x), IQR(x))
  names(result)<-c("N","Mean","SD","SE", "Min", "Max", "IQR")
  return(result)
}
sumstats<-aggregate(life_expectancy~schooling*status,data=Life,mysummary)
sumstats<-cbind(sumstats[,1:2],sumstats[,-(1:2)])
sumstats
```

```{r fig.width=20, fig.height=10}
ggplot(sumstats,aes(x=schooling,y=Mean,group=status,colour=status))+
  ylab("Life Expectancy")+
  geom_line()+
  geom_point()+
  geom_errorbar(aes(ymin=Mean-SD,ymax=Mean+SD),width=.1) +
  scale_color_manual(values = c("dodgerblue4", "#D55E00"));
```

```{r}
# Final model on whole data set
final.model<-lm(life_expectancy~schooling+status+schooling*status,data=Life)
summary(final.model)

plot(final.model$fitted.values,Life$life_expectancy,xlab="Predicted",ylab="Life Expectancy",xlim=c(40,90),ylim=c(20,100))
lines(c(40, 90),c(20,100),col="red")

```


```{r}
# Studentized Residuals
sres <- studres(model_fit)
hist(sres, freq=FALSE,
     main="Distribution of Studentized Residuals", xlab="Residuals")
xfit<-seq(min(sres-1),max(sres)+1,length=60)
yfit<-dnorm(xfit)
lines(xfit, yfit, col="darkblue", lwd=2)

```
#### Hypothesis test

The full model used here includes schooling, status, and the interactions between schooling and status.  The reduced model status and schooling.
Ho:  Full model = Reduced Model
Ha:  Full model != Reduced Model
```{r}
full.model <- lm(life_expectancy~schooling+status+schooling*status,data=Life)
summary(full.model)
reduced.model <- lm(life_expectancy~schooling+status,data=Life)
summary(reduced.model)

```

**Conclusion:**  There is sufficient evidence that the full model is different than the reduced model (p-value < 0.0001) from a partial f-test.

```{r}
anova(reduced.model,full.model)
```

** Interpretation **
For every 1-year increase in schooling, the increase in the mean estimated life expectancy is .98 years for people in developed countries (p-value < 0.0001).  The life expectancy in Developing countries is estimated to be 19.5 years less than mean life expectancy in Developed countries (for countries with zero education), but for every year increase in schooling, the mean life expectancy is estimated to be 1.06 that of  Developed countries (p-value < 0.0001).  

** Confidence Intervals **
-TBD

#### Option 2 for interpretable model - use Random Forest for Model Selection

```{r, fig.width=12, fig.height=6}
# Random Forest Train/Test split
library(MASS)
library(randomForest)
set.seed(1234)
trainIndices = sample(1:nrow(Life), nrow(Life)/2)
tree.test = Life[-trainIndices,"life_expectancy"]

```

```{r}

# Prediction
rf.le = randomForest(life_expectancy~.,data=Life,subset=trainIndices, mtry=6, importance=TRUE)
yhat.rf = predict(rf.le, newdata = test)
mean((yhat.rf-tree.test)^2)

# Plot
plot(yhat.rf,tree.test)
abline(0,1)
mean((yhat.bag-tree.test)^2)

# Importance of variables
importance(rf.le)
varImpPlot(rf.le)

```

```{r}
# Create a multiple regression model using the variables found above (hiv_aids + income_composition_of_resources + adult_mortality + schooling + status)
set.seed(1234)
trainIndicesLM = sample(seq(1:dim(Life)[1]),round(.7*dim(Life)[1]))
trainLM = Life[trainIndicesLM,]
testLM = Life[-trainIndicesLM,]
dim(trainLM)
dim(testLM)

```

```{r}
# Fit the model
model_fit <- lm(life_expectancy ~ hiv_aids + income_composition_of_resources + adult_mortality + schooling + status, data=trainLM)
summary(model_fit)

model_pre <- predict(model_fit, interval = "predict", newdata=testLM)
model_pre

```

```{r}
MSPE <- mean((model_pre[,1] - testLM$life_expectancy)^2)
MSPE
            
```

```{r}
# Final model on whole data set
final.model<-lm(life_expectancy~hiv_aids + income_composition_of_resources + adult_mortality + schooling + status,data=Life)
summary(final.model)

plot(final.model$fitted.values,Life$life_expectancy,xlab="Predicted",ylab="Life Expectancy",xlim=c(40,90),ylim=c(20,100))
lines(c(40, 90),c(20,100),col="red")

```

**Compare Results to Fwd, Bwd, Stepwise, LASSO**


#### Hypothesis test
The full model used here includes all the variables selected from a stepwise regression.  The reduced model includes the top variables from a Random Forest along with the status variable.
Ho:  Full model = Reduced Model
Ha:  Full model != Reduced Model
```{r}
# Build full and reduced models
reduced.model <- lm(life_expectancy~hiv_aids + income_composition_of_resources + adult_mortality + schooling + status,data=Life)
summary(reduced.model)
full.model <- lm(life_expectancy~.-total_expenditure -hepatitis_b -alcohol -infant_deaths, data=Life)
summary(full.model)
```

**Conclusion:** The full model is significantly different than the reduced model (p-value < 0.001) from a partial f-test.
```{r}
# Build full and reduced models
anova(reduced.model,full.model)
```

**Interpretation:**
TBD

**Confidence Intervals**
TBD
